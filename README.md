# NLP-Journey

A follow up repository of [Jax-Journey](https://github.com/deterministic-algorithms-lab/Jax-Journey). This repository provides a selection of notebooks for various NLP tasks, which are completely see-through (i.e., you can see the implementation till the basic Jax/Haiku modules, in a single notebook). These were meant to be used as further tutorials in Jax for NLP, and as a guide for the coding style followed in this [awesome article](https://www.pragmatic.ml/finetuning-transformers-with-jax-and-haiku/) by Madison May. 

These notebooks, although mostly code, also mention the nuanced features, often missed when using off-the-shelf models. Moreover, they allow you to optimize everything right to the innermost modules. Also, we mention how to adapt the model to your use case, in each notebook. 

## Transformer for Sequence Classification

A basic introductory notebook consisting of the original [RoBERTa initialized version](https://github.com/deterministic-algorithms-lab/NLP-Journey/blob/main/classification/basic_transformer.ipynb) and [randomly initialized version](https://github.com/deterministic-algorithms-lab/NLP-Journey/blob/main/classification/transformer_to_pretrain.ipynb) .

## Transformers for Language Modelling Tasks

