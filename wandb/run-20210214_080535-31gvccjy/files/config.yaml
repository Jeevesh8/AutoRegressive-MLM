wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.10.18
    framework: huggingface
    huggingface_version: 4.3.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.0
    t:
      1:
      - 11
      2:
      - 11
      4: 3.7.0
      5: 0.10.18
      6: 4.3.2
attention_drop_rate:
  desc: null
  value: 0.1
d_model:
  desc: null
  value: 768
data_folders:
  desc: null
  value:
  - /content/drive/MyDrive/Argumentation/first_batch_data/
discourse_markers_file:
  desc: null
  value: /content/drive/MyDrive/Argumentation/first_batch_data/Discourse_Markers.txt
dsm_list:
  desc: null
  value:
  - null
  - null
  - null
  - null
  - null
  - 19726
  - null
  - null
  - null
  - null
  - null
  - 23372
  - 18401
  - 24648
  - null
  - 36895
  - null
  - null
  - 13437
  - 30117
  - 281
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - 32931
  - null
  - null
  - null
  - 1594
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - null
  - 50268
  - null
  - null
  - 50269
  - 2527
  - null
  - null
  - 25800
  - 8569
  - 12196
  - 9178
  - 14746
  - 4297
  - null
  - null
  - null
  - null
  - null
  - 20235
  - null
  - 50271
embed_dropout_rate:
  desc: null
  value: 0.1
eos_id:
  desc: null
  value: 2
extra_tokens:
  desc: null
  value:
  - <url>
  - <startq>
  - <endq>
  - firstly
  - lastly
  - n't
  - tldr
  - <author_0>
  - <author_1>
  - <author_2>
  - <author_3>
  - <author_4>
  - <author_5>
  - <author_6>
  - <author_7>
featurizer_batch_size:
  desc: null
  value: 4
featurizer_max_length:
  desc: null
  value: 128
fully_connected_drop_rate:
  desc: null
  value: 0.1
hidden_size:
  desc: null
  value: 768
initialize_pretrained:
  desc: null
  value: distilroberta-base
intermediate_size:
  desc: null
  value: 3072
l2:
  desc: null
  value: 0.1
last_layer:
  desc: null
  value: ''
learning_rate:
  desc: null
  value: 1.0e-05
mask_id:
  desc: null
  value: 50264
max_grad_norm:
  desc: null
  value: 1.0
max_labelled_users_per_tree:
  desc: null
  value: 8
max_length:
  desc: null
  value: 512
max_losses:
  desc: null
  value: 10
max_tree_size:
  desc: null
  value: 20
mlm_batch_size:
  desc: null
  value: 4
n_epochs:
  desc: null
  value: 10
n_heads:
  desc: null
  value: 12
n_layers:
  desc: null
  value: 6
pad_id:
  desc: null
  value: 1
params_dir:
  desc: null
  value: /content/drive/MyDrive/2SCL/Argumentation/
pre_training:
  desc: null
  value: true
pt_hf_tokenizer:
  desc: null
  value: 'PreTrainedTokenizer(name_or_path=''distilroberta-base'', vocab_size=50265,
    model_max_len=512, is_fast=False, padding_side=''right'', special_tokens={''bos_token'':
    AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=True),
    ''eos_token'': AddedToken("</s>", rstrip=False, lstrip=False, single_word=False,
    normalized=True), ''unk_token'': AddedToken("<unk>", rstrip=False, lstrip=False,
    single_word=False, normalized=True), ''sep_token'': AddedToken("</s>", rstrip=False,
    lstrip=False, single_word=False, normalized=True), ''pad_token'': AddedToken("<pad>",
    rstrip=False, lstrip=False, single_word=False, normalized=True), ''cls_token'':
    AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=True),
    ''mask_token'': AddedToken("<mask>", rstrip=False, lstrip=True, single_word=False,
    normalized=True)})'
restart_from:
  desc: null
  value: 0
sos_id:
  desc: null
  value: 0
total_steps:
  desc: null
  value: 251142
vocab_size:
  desc: null
  value: 50280
